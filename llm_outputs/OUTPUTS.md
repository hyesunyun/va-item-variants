# Description of Contents

As part of the supplementary materials, we include the LLM-generated item (question) variants and content we included in the `ITEM VARIANTS PLUS` condition. The following provides descriptions of each `csv` file.

## Dataset of LLM-Generated PROMISÂ® Short Form Depression Questionnaire (version 8a)

***[questionnaire_item_variants.csv](questionnaire_item_variants.csv)***
The full dataset contains all 67 item (question) variants generated by ChatGPT that were used in the evaluation study. 
We originally generated 7 variants per item using GPT-3 and 20 variants per item using ChatGPT. Then, we filtered out duplicate values to get the 178 variants. Interestingly, we found ChatGPT-generated questions were more conversational and better suited for agent dialogue but found that they could deviate from the original PROMIS statement, so we employed the expertise of a psychologist to filter out low-quality ones. After the expert-led filtering, we ended up exclusively using ChatGPT-generated outputs as they provided more diverse variants than GPT-3.

## Dataset of LLM-Generated Personal Anecdotes

***[llm_generated_personal_anecdotes.csv](llm_generated_personal_anecdotes.csv)***
The full dataset contains 37 personal anecdotes generated by GPT-3 that were used in the evaluation study. Participants in the `ITEM VARIANTS PLUS` condition were given a randomly selected anecdote during each session with the virtual agent. 

Originally, 320 anecdotes were generated using GPT-3. Then, we filtered them based on length as we did not want the agent interaction to be significantly longer than the CONTROL group. We had two research assistants go through each output and rated them on a scale of 1-5 on its appropriateness for our conversational context and whether or not the text stories translated well with text-to-speech (TTS). We selected stories with ratings above a 3 and those that passed the TTS test.

## Dataset of LLM-Generated Jokes

***[llm_generated_jokes.csv](llm_generated_jokes.csv)***
The full dataset contains 24 jokes generated by GPT-3 and ChatGPT that were used in the evaluation study. Participants in the `ITEM VARIANTS PLUS` condition were given a randomly selected joke during each session with the virtual agent.

A total of 225 unique jokes were generated using GPT-3 (20 times for each prompt) ChatGPT (5 times per prompt). After filtering out for duplicates, we were left with 146. Furthermore, we had annotators help with removing additional jokes that would be hard for the agent to deliver (due to limitations of TTS system) or that would be difficult for general audience to understand (specifically, puns).

## Dataset of LLM-Generated Empathetic Responses

***[llm_generated_empathetic_responses.csv](llm_generated_empathetic_responses.csv)***
The full dataset contains a total of 35 empathetic responses generated by GPT-3 that were used in the evaluation study. We generated empathetic responses for each question in the questionnaire and presented them to participants based on their responses to each question. The column labeled `response_for_original_item` indicates which item or question each empathetic response corresponds to.

We were able to generate 500 empathetic responses using GPT-3. We removed any duplicates and outputs that were longer than 25 words to keep the conversations concise. In addition, we had two research assistants go through each output and rated them on a scale of 1-5 on its appropriateness for our conversational context and whether or not the text stories translated well with text-to-speech (TTS). After filtering out the low quality ones, we ended up with 35 empathetic responses.

## Dataset of LLM-Generated Inspiring or Hopeful Messages

***[llm_generated_inspiring_messages.csv](llm_generated_inspiring_messages.csv)***
The full dataset contains 23 inspiring or hopeful messages generated by GPT-3 and ChatGPT that were used in the evaluation study. Participants in the `ITEM VARIANTS PLUS` condition were given a randomly selected message during each session with the virtual agent.

A total of 80 outputs were generated using GPT-3 and ChatGPT. Duplicates were filtered out and any outputs with a word count over 15 was removed. We had two research assistants go through each output and rated them on a scale of 1-5 on its appropriateness for our conversational context and whether or not the text stories translated well with text-to-speech (TTS). After filtering out the low quality ones, we ended up with 23 messages.

## Dataset of LLM-Generated Farewell Statements

***[llm_generated_farewell_statements.csv](llm_generated_farewell_statements.csv)***
The full dataset contains 42 farewell statements generated by GPT-3 and ChatGPT that were used in the evaluation study. Participants in the `ITEM VARIANTS PLUS` condition were given a randomly selected farewell during each session with the virtual agent.

A total of 80 outputs were generated using GPT-3 and ChatGPT. Duplicates were filtered out and any outputs with a word count over 15 was removed. We had two research assistants go through each output and rated them on a scale of 1-5 on its appropriateness for our conversational context and whether or not the text stories translated well with text-to-speech (TTS). After filtering out the low quality ones, we ended up with 42 statements..